{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "737f6270-4b0e-4e36-94b4-3bda44209b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from accelerate) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from accelerate) (5.8.0)\n",
      "Requirement already satisfied: pyyaml in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./.local/lib/python3.9/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in ./.local/lib/python3.9/site-packages (from accelerate) (0.30.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.9/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.local/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from packaging>=20.0->accelerate) (3.0.4)\n",
      "Requirement already satisfied: networkx in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2021.10.8)\n",
      "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "435cc0a1-3471-4be2-8887-98862d93d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "import torch\n",
    "import evaluate\n",
    "import re\n",
    "import traceback\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7a9900-5115-432c-9086-b87e844b60e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MBPP dataset from Hugging Face\n",
    "mbpp = load_dataset(\"mbpp\")\n",
    "train = mbpp[\"train\"]\n",
    "test = mbpp[\"test\"]\n",
    "validation = mbpp[\"validation\"]\n",
    "prompt = mbpp[\"prompt\"]\n",
    "\n",
    "# Combine into one dataset\n",
    "full_mbpp = concatenate_datasets([train, test, validation, prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b20eeeb-4578-4c74-ba81-ef9a1111ebd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['task_id', 'text', 'code', 'test_list', 'test_setup_code', 'challenge_test_list'],\n",
       "    num_rows: 974\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_mbpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4af2d81f-80a9-4d52-8c58-a0af99ffb146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"Qwen/Qwen2.5-Coder-0.5B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "085662a9-4d09-4935-844b-c727a2a54239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code(prompt):\n",
    "\n",
    "    system_prompt = \"You are a coding assistant. When given a prompt that includes a function signature and docstring, generate only the function body (the indented code that implements the function). Do not include the function definition (i.e. do not output the 'def' line), imports, or docstring. Do not include any extra text, comments, or explanations. Your output should consist solely of the indented code that can directly follow a function signature.\"\n",
    "\n",
    "    prompt = system_prompt + prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_new_tokens=512,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        attention_mask = attention_mask\n",
    "    )\n",
    "    \n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    assistant_response = full_response.split(\"assistant\\n\")[-1].strip()\n",
    "    \n",
    "    return full_response[len(system_prompt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d615ad08-be6a-4134-953f-eb52bb761634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_block(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the top code block from a model's response.\n",
    "    Starts from first 'import', 'def', or comment line, and stops before '# Example usage'.\n",
    "    \"\"\"\n",
    "    # Split into lines\n",
    "    lines = text.splitlines()\n",
    "    \n",
    "    code_lines = []\n",
    "    capturing = False\n",
    "\n",
    "    for line in lines:\n",
    "        # Start capturing if we see something that looks like code\n",
    "        if not capturing and (line.strip().startswith(\"def\") or \n",
    "                              line.strip().startswith(\"import\") or \n",
    "                              line.strip().startswith(\"from\") or\n",
    "                              line.strip().startswith(\"#\")):\n",
    "            capturing = True\n",
    "\n",
    "        # Stop capturing if we hit example usage\n",
    "        if capturing:\n",
    "            if re.match(r\"#\\s*Example usage\", line, re.IGNORECASE):\n",
    "                break\n",
    "            code_lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(code_lines).strip() if code_lines else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188ffcc9-7835-421d-b03b-bf7c8d338e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_code_with_tests(code: str, test_cases: list[str]) -> float:\n",
    "    \"\"\"\n",
    "    Executes a given code string and runs test cases (as strings).\n",
    "    Returns the fraction of tests that pass.\n",
    "    \"\"\"\n",
    "    passed = 0\n",
    "    total = len(test_cases)\n",
    "\n",
    "    # Run the code in an isolated environment\n",
    "    local_env = {}\n",
    "    try:\n",
    "        exec(code, local_env)\n",
    "    except Exception as e:\n",
    "        print(\"Code failed to compile:\", e)\n",
    "        return 0.0  # Bail out if the function is invalid\n",
    "\n",
    "    for test in test_cases:\n",
    "        try:\n",
    "            exec(test, local_env)\n",
    "            passed += 1\n",
    "        except Exception:\n",
    "            print(f\"Test failed: {test}\")\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "    return round(passed / total, 2) if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20dd922e-6c7b-43ac-a0d7-efb9dc86b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, file_path):\n",
    "    with open(file_path, \"a\") as f:\n",
    "        for item in data:\n",
    "            json.dump(item, f)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3593061d-a74a-498a-bfeb-15d701ad3b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['task_id', 'text', 'code', 'test_list', 'test_setup_code', 'challenge_test_list'],\n",
       "    num_rows: 974\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_mbpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6aa9975-9e7c-4f99-8e39-c9b45c54d523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 601,\n",
       " 'text': 'Write a function to find the longest chain which can be formed from the given set of pairs.',\n",
       " 'code': 'class Pair(object): \\r\\n\\tdef __init__(self, a, b): \\r\\n\\t\\tself.a = a \\r\\n\\t\\tself.b = b \\r\\ndef max_chain_length(arr, n): \\r\\n\\tmax = 0\\r\\n\\tmcl = [1 for i in range(n)] \\r\\n\\tfor i in range(1, n): \\r\\n\\t\\tfor j in range(0, i): \\r\\n\\t\\t\\tif (arr[i].a > arr[j].b and\\r\\n\\t\\t\\t\\tmcl[i] < mcl[j] + 1): \\r\\n\\t\\t\\t\\tmcl[i] = mcl[j] + 1\\r\\n\\tfor i in range(n): \\r\\n\\t\\tif (max < mcl[i]): \\r\\n\\t\\t\\tmax = mcl[i] \\r\\n\\treturn max',\n",
       " 'test_list': ['assert max_chain_length([Pair(5, 24), Pair(15, 25),Pair(27, 40), Pair(50, 60)], 4) == 3',\n",
       "  'assert max_chain_length([Pair(1, 2), Pair(3, 4),Pair(5, 6), Pair(7, 8)], 4) == 4',\n",
       "  'assert max_chain_length([Pair(19, 10), Pair(11, 12),Pair(13, 14), Pair(15, 16), Pair(31, 54)], 5) == 5'],\n",
       " 'test_setup_code': '',\n",
       " 'challenge_test_list': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_mbpp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a844bd-4935-446b-9351-c711ee4eaeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''#Write a python function to remove first and last occurrence of a given character from the string.\n",
    "def remove_Occ(s,ch):'''\n",
    "response = generate_code(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58e48a35-a57e-4f97-96f2-d82e3dc6f4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "974"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_mbpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bc27ee2-ddb9-4344-8662-6e4a4badf4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 602,\n",
       " 'text': 'Write a python function to find the first repeated character in a given string.',\n",
       " 'code': 'def first_repeated_char(str1):\\r\\n  for index,c in enumerate(str1):\\r\\n    if str1[:index+1].count(c) > 1:\\r\\n      return c \\r\\n  return \"None\"',\n",
       " 'test_list': ['assert first_repeated_char(\"abcabc\") == \"a\"',\n",
       "  'assert first_repeated_char(\"abc\") == \"None\"',\n",
       "  'assert first_repeated_char(\"123123\") == \"1\"'],\n",
       " 'test_setup_code': '',\n",
       " 'challenge_test_list': []}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_mbpp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e307a658-a796-4d83-b550-0cd475142151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test failed: assert max_chain_length([Pair(5, 24), Pair(15, 25),Pair(27, 40), Pair(50, 60)], 4) == 3\n",
      "Test failed: assert max_chain_length([Pair(1, 2), Pair(3, 4),Pair(5, 6), Pair(7, 8)], 4) == 4\n",
      "Test failed: assert max_chain_length([Pair(19, 10), Pair(11, 12),Pair(13, 14), Pair(15, 16), Pair(31, 54)], 5) == 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15096/2250951485.py\", line 19, in evaluate_code_with_tests\n",
      "    exec(test, local_env)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "NameError: name 'max_chain_length' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15096/2250951485.py\", line 19, in evaluate_code_with_tests\n",
      "    exec(test, local_env)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "NameError: name 'max_chain_length' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15096/2250951485.py\", line 19, in evaluate_code_with_tests\n",
      "    exec(test, local_env)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "NameError: name 'max_chain_length' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code failed to compile: invalid syntax (<string>, line 21)\n",
      "Test failed: assert get_ludic(10) == [1, 2, 3, 5, 7]\n",
      "Test failed: assert get_ludic(25) == [1, 2, 3, 5, 7, 11, 13, 17, 23, 25]\n",
      "Test failed: assert get_ludic(45) == [1, 2, 3, 5, 7, 11, 13, 17, 23, 25, 29, 37, 41, 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15096/2250951485.py\", line 19, in evaluate_code_with_tests\n",
      "    exec(test, local_env)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15096/2250951485.py\", line 19, in evaluate_code_with_tests\n",
      "    exec(test, local_env)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15096/2250951485.py\", line 19, in evaluate_code_with_tests\n",
      "    exec(test, local_env)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "AssertionError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code failed to compile: invalid syntax (<string>, line 9)\n",
      "Code failed to compile: invalid syntax (<string>, line 11)\n",
      "Code failed to compile: invalid syntax (<string>, line 6)\n",
      "Test failed: assert find_literals('The quick brown fox jumps over the lazy dog.', 'fox') == ('fox', 16, 19)\n",
      "Test failed: assert find_literals('Its been a very crazy procedure right', 'crazy') == ('crazy', 16, 21)\n",
      "Test failed: assert find_literals('Hardest choices required strongest will', 'will') == ('will', 35, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15096/2250951485.py\", line 19, in evaluate_code_with_tests\n",
      "    exec(test, local_env)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15096/2250951485.py\", line 19, in evaluate_code_with_tests\n",
      "    exec(test, local_env)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15096/2250951485.py\", line 19, in evaluate_code_with_tests\n",
      "    exec(test, local_env)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "AssertionError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test failed: assert bell_Number(3) == 5\n",
      "Test failed: assert bell_Number(4) == 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15096/2250951485.py\", line 19, in evaluate_code_with_tests\n",
      "    exec(test, local_env)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15096/2250951485.py\", line 19, in evaluate_code_with_tests\n",
      "    exec(test, local_env)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "AssertionError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code failed to compile: EOL while scanning string literal (<string>, line 6)\n",
      "Test failed: assert remove_kth_element([1,1,2,3,4,4,5,1],3)==[1, 1, 3, 4, 4, 5, 1]\n",
      "Test failed: assert remove_kth_element([0, 0, 1, 2, 3, 4, 4, 5, 6, 6, 6, 7, 8, 9, 4, 4],4)==[0, 0, 1, 3, 4, 4, 5, 6, 6, 6, 7, 8, 9, 4, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15096/2250951485.py\", line 19, in evaluate_code_with_tests\n",
      "    exec(test, local_env)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15096/2250951485.py\", line 19, in evaluate_code_with_tests\n",
      "    exec(test, local_env)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(10):\n",
    "    d1 = {}\n",
    "    d2 = {}\n",
    "    \n",
    "    d2['prompt'] = full_mbpp[i]['text']\n",
    "    d2['code'] = full_mbpp[i]['code']\n",
    "    d2['score'] = 1\n",
    "    \n",
    "    index = full_mbpp[i]['code'].index(':')\n",
    "    prompt = '#' + full_mbpp[i]['text'] + '\\n' + full_mbpp[i]['code'][:index+1]\n",
    "    response = generate_code(prompt)\n",
    "    code = extract_code_block(response)\n",
    "    \n",
    "    if code != None:\n",
    "        test_cases = full_mbpp[i]['test_list']\n",
    "        score = evaluate_code_with_tests(code, test_cases)\n",
    "        \n",
    "        d1['prompt'] = prompt\n",
    "        d1['code'] = code\n",
    "        d1['score'] = score\n",
    "    if len(d1) != 0:\n",
    "        data.append(d1)\n",
    "    data.append(d2)\n",
    "    \n",
    "    if len(data) > 10:\n",
    "        file_path = 'generator_rewards.jsonl'\n",
    "        save_data(data, file_path)\n",
    "        data = []\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
